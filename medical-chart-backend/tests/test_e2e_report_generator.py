"""
Level 3 E2Eãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«: Level 3 (End-to-End)
ç›®çš„: E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã®è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
è¨­è¨ˆæ›¸å‚ç…§: doc_08_test_generation.md
æ›´æ–°æ—¥: 2025-01-15

ä½¿ç”¨æ–¹æ³•:
python tests/test_e2e_report_generator.py
"""

import json
import os
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from pathlib import Path

import pytest


@dataclass
class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    test_name: str
    test_class: str
    status: str  # "passed", "failed", "skipped"
    duration: float
    error_message: Optional[str] = None
    failure_details: Optional[str] = None
    test_level: str = "Level 3"
    test_category: str = "E2E"


@dataclass
class TestSummary:
    """ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    total_tests: int
    passed_tests: int
    failed_tests: int
    skipped_tests: int
    success_rate: float
    total_duration: float
    test_level: str
    execution_date: str


class E2ETestReportGenerator:
    """Level 3 E2Eãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "tests/reports"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.test_results: List[TestResult] = []
        self.start_time = time.time()
        self.execution_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def add_test_result(self, result: TestResult):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’è¿½åŠ """
        self.test_results.append(result)
    
    def generate_summary(self) -> TestSummary:
        """ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r.status == "passed"])
        failed_tests = len([r for r in self.test_results if r.status == "failed"])
        skipped_tests = len([r for r in self.test_results if r.status == "skipped"])
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        total_duration = sum(r.duration for r in self.test_results)
        
        return TestSummary(
            total_tests=total_tests,
            passed_tests=passed_tests,
            failed_tests=failed_tests,
            skipped_tests=skipped_tests,
            success_rate=success_rate,
            total_duration=total_duration,
            test_level="Level 3",
            execution_date=self.execution_date
        )
    
    def generate_markdown_report(self) -> str:
        """Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        summary = self.generate_summary()
        
        report = f"""# Level 3 E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ

## åŸºæœ¬æƒ…å ±
- **ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«**: {summary.test_level} (End-to-End)
- **å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **å®Ÿè¡Œç’°å¢ƒ**: Test Environment
- **å¯¾è±¡å®Ÿè£…**: Backend API Endpoints
- **ãƒ†ã‚¹ãƒˆç¯„å›²**: Full Stack E2E

## ãƒ†ã‚¹ãƒˆæ¦‚è¦

### ãƒ†ã‚¹ãƒˆç›®çš„
APIçµŒç”±ã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ¤œè¨¼ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç¢ºèªã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ¤œè¨¼ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®æ¤œè¨¼

### æ¤œè¨¼å¯¾è±¡
- ãƒãƒ£ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€œçµæœå–å¾—ã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæŒ‡å®šå‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã¨æ•´åˆæ€§
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«
- **ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯**: 90%
- **å¤–éƒ¨é€£æº**: 85%
- **å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: 90%

## ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼

| é …ç›® | å€¤ |
|------|-----|
| ç·ãƒ†ã‚¹ãƒˆæ•° | {summary.total_tests} |
| æˆåŠŸ | {summary.passed_tests} |
| å¤±æ•— | {summary.failed_tests} |
| ã‚¹ã‚­ãƒƒãƒ— | {summary.skipped_tests} |
| æˆåŠŸç‡ | {summary.success_rate:.1f}% |
| ç·å®Ÿè¡Œæ™‚é–“ | {summary.total_duration:.2f}ç§’ |

## è©³ç´°ãƒ†ã‚¹ãƒˆçµæœ

"""
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ†ã‚¹ãƒˆçµæœã‚’æ•´ç†
        categories = {}
        for result in self.test_results:
            category = result.test_category
            if category not in categories:
                categories[category] = []
            categories[category].append(result)
        
        for category, results in categories.items():
            report += f"### {category}ãƒ†ã‚¹ãƒˆ\n\n"
            report += "| ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ | çµæœ | å®Ÿè¡Œæ™‚é–“ | å‚™è€ƒ |\n"
            report += "|-------------|------|----------|------|\n"
            
            for result in results:
                status_icon = "âœ…" if result.status == "passed" else "âŒ" if result.status == "failed" else "â­ï¸"
                error_note = result.error_message[:50] + "..." if result.error_message else ""
                
                report += f"| {result.test_name} | {status_icon} {result.status} | {result.duration:.2f}s | {error_note} |\n"
            
            report += "\n"
        
        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°
        failed_tests = [r for r in self.test_results if r.status == "failed"]
        if failed_tests:
            report += "## å¤±æ•—ãƒ†ã‚¹ãƒˆã®è©³ç´°\n\n"
            
            for result in failed_tests:
                report += f"### {result.test_name}\n"
                report += f"- **ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹**: {result.test_class}\n"
                report += f"- **å®Ÿè¡Œæ™‚é–“**: {result.duration:.2f}ç§’\n"
                report += f"- **ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸**: {result.error_message}\n"
                if result.failure_details:
                    report += f"- **è©³ç´°**:\n```\n{result.failure_details}\n```\n"
                report += "\n"
        
        # ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
        report += """## ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ

### æ©Ÿèƒ½ã‚«ãƒãƒ¬ãƒƒã‚¸
- **ãƒãƒ£ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **çµæœå–å¾—**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ©Ÿèƒ½**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿

### APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸
- `POST /api/v1/charts`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `POST /api/v1/charts/upload`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `GET /api/v1/charts/{chart_id}/status`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `GET /api/v1/charts/{chart_id}`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `GET /api/v1/charts/{chart_id}/review-items`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `PATCH /api/v1/charts/{chart_id}/items/{item_id}`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `POST /api/v1/templates`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿
- `DELETE /api/v1/templates/{template_id}`: âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿

"""
        
        # å“è³ªè©•ä¾¡
        if summary.success_rate >= 95:
            quality_status = "å„ªç§€"
            quality_color = "ğŸŸ¢"
        elif summary.success_rate >= 80:
            quality_status = "è‰¯å¥½"
            quality_color = "ğŸŸ¡"
        else:
            quality_status = "è¦æ”¹å–„"
            quality_color = "ğŸ”´"
        
        report += f"""## å“è³ªè©•ä¾¡

### ä¿¡é ¼æ€§è©•ä¾¡
- **ç¾åœ¨ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«**: {summary.success_rate:.1f}%
- **ç›®æ¨™ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«**: 90%
- **é”æˆçŠ¶æ³**: {quality_color} {quality_status}

### ãƒªã‚¹ã‚¯è©•ä¾¡
"""
        
        if summary.success_rate >= 90:
            report += "- **é«˜ãƒªã‚¹ã‚¯é ˜åŸŸ**: ãªã—\n"
            report += "- **ä¸­ãƒªã‚¹ã‚¯é ˜åŸŸ**: ãªã—\n"
            report += "- **ä½ãƒªã‚¹ã‚¯é ˜åŸŸ**: å…¨æ©Ÿèƒ½\n"
        elif summary.success_rate >= 80:
            report += "- **é«˜ãƒªã‚¹ã‚¯é ˜åŸŸ**: ãªã—\n"
            report += "- **ä¸­ãƒªã‚¹ã‚¯é ˜åŸŸ**: ä¸€éƒ¨æ©Ÿèƒ½\n"
            report += "- **ä½ãƒªã‚¹ã‚¯é ˜åŸŸ**: ä¸»è¦æ©Ÿèƒ½\n"
        else:
            report += "- **é«˜ãƒªã‚¹ã‚¯é ˜åŸŸ**: è¤‡æ•°æ©Ÿèƒ½\n"
            report += "- **ä¸­ãƒªã‚¹ã‚¯é ˜åŸŸ**: ä¸»è¦æ©Ÿèƒ½\n"
            report += "- **ä½ãƒªã‚¹ã‚¯é ˜åŸŸ**: é™å®šçš„\n"
        
        # æ¨å¥¨äº‹é …
        report += """
## æ¨å¥¨äº‹é …

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
"""
        
        if summary.success_rate >= 95:
            report += """1. æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™
2. ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šã®ç¢ºèª
3. é‹ç”¨æ‰‹é †æ›¸ã®æœ€çµ‚ç¢ºèª
"""
        elif summary.success_rate >= 80:
            report += """1. å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ä¿®æ­£
2. è¿½åŠ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®æ¤œè¨
3. å†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
"""
        else:
            report += """1. å¤±æ•—åŸå› ã®è©³ç´°èª¿æŸ»
2. å®Ÿè£…ã®è¦‹ç›´ã—
3. ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ç¢ºèª
"""
        
        report += f"""
### è¿½åŠ ãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§
- **Level 4ãƒ†ã‚¹ãƒˆï¼ˆFrontendï¼‰**: æ¨å¥¨
- **Level 5ãƒ†ã‚¹ãƒˆï¼ˆFull Stack E2Eï¼‰**: å¿…è¦ã«å¿œã˜ã¦
- **è¿½åŠ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹**: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã€è² è·ãƒ†ã‚¹ãƒˆ

## æŠ€è¡“çš„è©³ç´°

### ä½¿ç”¨æŠ€è¡“
- **ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: pytest
- **HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ**: FastAPI TestClient
- **ãƒ†ã‚¹ãƒˆç’°å¢ƒ**: Test Database, Mock Services

### å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰
```bash
# å…¨E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/test_e2e_*.py -v -m e2e

# ç‰¹å®šãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹å®Ÿè¡Œ
pytest tests/test_e2e_api_workflows.py::TestLevel3ChartWorkflow -v

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä»˜ãå®Ÿè¡Œ
pytest tests/test_e2e_*.py -v -m e2e --html=reports/e2e_report.html
```

### ç’°å¢ƒè¨­å®š
```yaml
test_environment:
  database: test_db
  api_key: test-api-key
  gcs_bucket: test-bucket
  timeout: 120s
```

## ä»˜éŒ²

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
- ãƒ†ã‚¹ãƒˆç”»åƒ: 800x600 JPEGå½¢å¼
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: 3é …ç›®ï¼ˆä¸»è¨´ã€ç¾ç—…æ­´ã€æ—¢å¾€æ­´ï¼‰
- APIã‚­ãƒ¼: test-api-key

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: < 5ç§’
- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: < 2ç§’
- å‡¦ç†å®Œäº†æ™‚é–“: < 120ç§’

---
*ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«: Level 3 (End-to-End)*
*ä¿¡é ¼æ€§: å…¨ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ 90%*
"""
        
        return report
    
    def save_report(self, format: str = "markdown") -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if format == "markdown":
            content = self.generate_markdown_report()
            filename = f"level3_e2e_test_report_{self.execution_date}.md"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return str(filepath)
        
        elif format == "json":
            summary = self.generate_summary()
            data = {
                "summary": asdict(summary),
                "test_results": [asdict(result) for result in self.test_results],
                "execution_metadata": {
                    "start_time": self.start_time,
                    "end_time": time.time(),
                    "execution_date": self.execution_date
                }
            }
            
            filename = f"level3_e2e_test_data_{self.execution_date}.json"
            filepath = self.output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            return str(filepath)
        
        else:
            raise ValueError(f"Unsupported format: {format}")
    
    def print_summary(self):
        """ã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›"""
        summary = self.generate_summary()
        
        print("\n" + "="*60)
        print("Level 3 E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼")
        print("="*60)
        print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {summary.total_tests}")
        print(f"æˆåŠŸ: {summary.passed_tests}")
        print(f"å¤±æ•—: {summary.failed_tests}")
        print(f"ã‚¹ã‚­ãƒƒãƒ—: {summary.skipped_tests}")
        print(f"æˆåŠŸç‡: {summary.success_rate:.1f}%")
        print(f"ç·å®Ÿè¡Œæ™‚é–“: {summary.total_duration:.2f}ç§’")
        
        if summary.success_rate >= 95:
            print("ğŸŸ¢ å“è³ªè©•ä¾¡: å„ªç§€")
        elif summary.success_rate >= 80:
            print("ğŸŸ¡ å“è³ªè©•ä¾¡: è‰¯å¥½")
        else:
            print("ğŸ”´ å“è³ªè©•ä¾¡: è¦æ”¹å–„")
        
        print("="*60)


class E2ETestCollector:
    """E2Eãƒ†ã‚¹ãƒˆçµæœåé›†å™¨"""
    
    def __init__(self):
        self.report_generator = E2ETestReportGenerator()
    
    def pytest_runtest_logreport(self, report):
        """pytestã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã‚’åé›†"""
        if report.when == "call":  # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚ºã®ã¿
            test_result = TestResult(
                test_name=report.nodeid.split("::")[-1],
                test_class=report.nodeid.split("::")[-2] if "::" in report.nodeid else "Unknown",
                status="passed" if report.passed else "failed" if report.failed else "skipped",
                duration=report.duration,
                error_message=str(report.longrepr) if report.failed else None,
                failure_details=report.longreprtext if hasattr(report, 'longreprtext') else None,
                test_level="Level 3",
                test_category="E2E"
            )
            
            self.report_generator.add_test_result(test_result)
    
    def pytest_sessionfinish(self, session, exitstatus):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        markdown_path = self.report_generator.save_report("markdown")
        print(f"\nğŸ“Š Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {markdown_path}")
        
        # JSONãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        json_path = self.report_generator.save_report("json")
        print(f"ğŸ“Š JSONãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {json_path}")
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        self.report_generator.print_summary()


def create_sample_test_results():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆçµæœã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰"""
    generator = E2ETestReportGenerator()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆçµæœ
    sample_results = [
        TestResult("test_complete_chart_upload_workflow", "TestLevel3ChartWorkflow", "passed", 45.2),
        TestResult("test_chart_upload_with_template_workflow", "TestLevel3ChartWorkflow", "passed", 52.8),
        TestResult("test_complete_review_workflow", "TestLevel3ReviewWorkflow", "passed", 38.5),
        TestResult("test_chart_data_persistence_workflow", "TestLevel3DataConsistency", "passed", 41.3),
        TestResult("test_concurrent_data_consistency", "TestLevel3DataConsistency", "passed", 28.7),
        TestResult("test_review_data_consistency", "TestLevel3DataConsistency", "passed", 35.9),
        TestResult("test_invalid_file_upload_error_handling", "TestLevel3ErrorHandling", "passed", 2.1),
        TestResult("test_authentication_error_handling", "TestLevel3ErrorHandling", "passed", 1.8),
        TestResult("test_api_response_time_performance", "TestLevel3PerformanceAndSecurity", "passed", 8.4),
        TestResult("test_concurrent_requests_handling", "TestLevel3PerformanceAndSecurity", "passed", 15.6),
        TestResult("test_rollback_consistency", "TestLevel3TransactionConsistency", "failed", 5.2, 
                  "AssertionError: ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ã¾ã›ã‚“"),
    ]
    
    for result in sample_results:
        generator.add_test_result(result)
    
    return generator


if __name__ == "__main__":
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    print("Level 3 E2Eãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ‡ãƒ¢")
    
    generator = create_sample_test_results()
    
    # Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    markdown_path = generator.save_report("markdown")
    print(f"ğŸ“Š Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {markdown_path}")
    
    # JSONãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    json_path = generator.save_report("json")
    print(f"ğŸ“Š JSONãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {json_path}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    generator.print_summary()
    
    print(f"\nç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"- {markdown_path}")
    print(f"- {json_path}") 