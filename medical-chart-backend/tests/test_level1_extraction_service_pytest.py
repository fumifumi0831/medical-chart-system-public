"""
Level 1 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ: åŒ»ç™‚ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ
ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«: Level 1 (Unit Test)
ä¿¡é ¼æ€§: ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ 95%, ãƒ¢ãƒƒã‚¯ä½¿ç”¨
å®Ÿè¡Œé »åº¦: æ¯å›
å‰ææ¡ä»¶: ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹
è¨­è¨ˆæ›¸å‚ç…§: doc_04_detailed_design.md ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 4.2
æ›´æ–°æ—¥: 2025-01-15
"""

import json
import pytest
import asyncio
from datetime import datetime
from unittest.mock import patch, MagicMock, AsyncMock
from typing import List, Dict, Any

# å®Ÿéš›ã®å®Ÿè£…ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from app.services import (
        extract_raw_data_from_image,
        interpret_extracted_data,
        extract_and_interpret_data,
        calculate_levenshtein_similarity,
        calculate_semantic_similarity,
        should_review
    )
except ImportError:
    from app.services import gemini_service, similarity_service
    extract_raw_data_from_image = gemini_service.extract_raw_data_from_image
    interpret_extracted_data = gemini_service.interpret_extracted_data
    extract_and_interpret_data = gemini_service.extract_and_interpret_data
    calculate_levenshtein_similarity = similarity_service.calculate_levenshtein_similarity
    calculate_semantic_similarity = similarity_service.calculate_semantic_similarity
    should_review = similarity_service.should_review

from app.tasks.process_chart import process_extracted_items
from app.schemas.chart import ExtractedDataItem, ExtractedItemDetail


# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
@pytest.fixture
def sample_image_data():
    """ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒˆåˆ—ã®ãƒ¢ãƒƒã‚¯ï¼‰"""
    return b"mock_image_data"


@pytest.fixture
def sample_raw_items():
    """ã‚µãƒ³ãƒ—ãƒ«ç”ŸæŠ½å‡ºçµæœ"""
    return [
        {"item_name": "ä¸»è¨´", "raw_text": "é ­ç—›"},
        {"item_name": "ç¾ç—…æ­´", "raw_text": "3æ—¥å‰ã‹ã‚‰é ­ç—›ã‚ã‚Šã€å¸‚è²©è–¬ã§ä¸€æ™‚çš„ã«è»½å¿«ã™ã‚‹ãŒå†åº¦æ‚ªåŒ–"},
        {"item_name": "æ—¢å¾€æ­´", "raw_text": "ç·Šå¼µæ€§é ­ç—›ã®æ—¢å¾€ã‚ã‚Š"},
        {"item_name": "å®¶æ—æ­´", "raw_text": "ç‰¹è¨˜äº‹é …ãªã—"},
        {"item_name": "ç”Ÿæ´»æ­´", "raw_text": "å–«ç…™ãªã—ã€é£²é…’æ©Ÿä¼šé£²é…’"},
        {"item_name": "å†…æœè–¬ãƒ»ã‚µãƒ—ãƒª", "raw_text": "ãƒ­ã‚­ã‚½ãƒ‹ãƒ³é ­ç—›æ™‚"},
        {"item_name": "èº«ä½“æ‰€è¦‹", "raw_text": "è¡€åœ§120/80mmHgã€è„ˆæ‹72å›/åˆ†"}
    ]


@pytest.fixture
def sample_interpreted_items():
    """ã‚µãƒ³ãƒ—ãƒ«è§£é‡ˆçµæœ"""
    return [
        {"item_name": "ä¸»è¨´", "interpreted_text": "é ­ç—›"},
        {"item_name": "ç¾ç—…æ­´", "interpreted_text": "3æ—¥å‰ã‹ã‚‰é ­ç—›ãŒå‡ºç¾ã€‚å¸‚è²©è–¬ã§ä¸€æ™‚çš„ã«è»½å¿«ã™ã‚‹ãŒã€å†åº¦ç—‡çŠ¶ãŒæ‚ªåŒ–ã—ã¦ã„ã‚‹ã€‚"},
        {"item_name": "æ—¢å¾€æ­´", "interpreted_text": "ç·Šå¼µæ€§é ­ç—›ã®æ—¢å¾€æ­´ã‚ã‚Š"},
        {"item_name": "å®¶æ—æ­´", "interpreted_text": "ç‰¹è¨˜äº‹é …ãªã—"},
        {"item_name": "ç”Ÿæ´»æ­´", "interpreted_text": "å–«ç…™æ­´ãªã—ã€é£²é…’ã¯æ©Ÿä¼šé£²é…’"},
        {"item_name": "å†…æœè–¬ãƒ»ã‚µãƒ—ãƒª", "interpreted_text": "ãƒ­ã‚­ã‚½ãƒ‹ãƒ³ï¼ˆé ­ç—›æ™‚ã«æœç”¨ï¼‰"},
        {"item_name": "èº«ä½“æ‰€è¦‹", "interpreted_text": "è¡€åœ§120/80mmHgã€è„ˆæ‹72å›/åˆ†"}
    ]


class TestLevel1ExtractionService:
    """Level 1 æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ"""

    @pytest.mark.asyncio
    async def test_extract_raw_data_from_image(self, sample_image_data, sample_raw_items):
        """ç”»åƒã‹ã‚‰ã®ç”Ÿãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ï¼‰"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ãƒ¢ãƒƒã‚¯ã®è¨­å®š
            mock_model = MagicMock()
            mock_response = MagicMock()
            
            # 2æ®µéšã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ¢ãƒƒã‚¯
            mock_raw_response = MagicMock()
            mock_raw_response.text = "é ­ç—›ã€3æ—¥å‰ã‹ã‚‰é ­ç—›ã‚ã‚Šã€ç·Šå¼µæ€§é ­ç—›ã®æ—¢å¾€ã‚ã‚Š"
            
            mock_structured_response = MagicMock()
            mock_structured_response.text = json.dumps(sample_raw_items)
            
            mock_model.generate_content.side_effect = [mock_raw_response, mock_structured_response]
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # å®Ÿè¡Œ
            result = await extract_raw_data_from_image(sample_image_data)
            
            # æ¤œè¨¼
            assert isinstance(result, list)
            assert len(result) > 0
            assert all('item_name' in item and 'raw_text' in item for item in result)
            assert mock_genai.configure.call_count >= 1
            assert mock_genai.GenerativeModel.call_count >= 1
            assert mock_model.generate_content.call_count >= 2

    @pytest.mark.asyncio
    async def test_interpret_extracted_data(self, sample_raw_items, sample_interpreted_items):
        """ãƒ†ã‚­ã‚¹ãƒˆè§£é‡ˆãƒ»æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ï¼‰"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ãƒ¢ãƒƒã‚¯ã®è¨­å®š
            mock_model = MagicMock()
            mock_response = MagicMock()
            mock_response.text = json.dumps(sample_interpreted_items)
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # å®Ÿè¡Œ
            result = await interpret_extracted_data(sample_raw_items)
            
            # æ¤œè¨¼
            assert isinstance(result, list)
            assert len(result) > 0
            assert all('item_name' in item and 'interpreted_text' in item for item in result)
            assert mock_genai.configure.call_count >= 1
            assert mock_genai.GenerativeModel.call_count >= 1
            assert mock_model.generate_content.call_count >= 1

    @pytest.mark.asyncio
    async def test_extract_and_interpret_data(self, sample_image_data, sample_raw_items, sample_interpreted_items):
        """çµ±åˆæŠ½å‡ºå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ï¼‰"""
        with patch('app.services.gemini_service.extract_raw_data_from_image') as mock_raw, \
             patch('app.services.gemini_service.interpret_extracted_data') as mock_interpret:
            
            # ãƒ¢ãƒƒã‚¯ã®è¨­å®š
            mock_raw.return_value = sample_raw_items
            mock_interpret.return_value = sample_interpreted_items
            
            # å®Ÿè¡Œ
            raw_result, interpreted_result = await extract_and_interpret_data(sample_image_data)
            
            # æ¤œè¨¼
            assert isinstance(raw_result, list)
            assert isinstance(interpreted_result, list)
            assert len(raw_result) > 0
            assert len(interpreted_result) > 0
            assert mock_raw.call_count == 1
            assert mock_interpret.call_count == 1

    def test_calculate_levenshtein_similarity(self):
        """ãƒ¬ãƒ¼ãƒ™ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            ("é ­ç—›", "é ­ç—›", 1.0),  # å®Œå…¨ä¸€è‡´
            ("é ­ç—›", "ãšã¤ã†", 0.0),  # å®Œå…¨ä¸ä¸€è‡´
            ("3æ—¥å‰ã‹ã‚‰é ­ç—›ã‚ã‚Š", "3æ—¥å‰ã‹ã‚‰é ­ç—›ãŒå‡ºç¾", 0.5),  # éƒ¨åˆ†ä¸€è‡´
            ("", "", 1.0),  # ä¸¡æ–¹ç©ºæ–‡å­—
            ("é ­ç—›", "", 0.0),  # ç‰‡æ–¹ç©ºæ–‡å­—
            (None, None, 1.0),  # ä¸¡æ–¹None
            ("é ­ç—›", None, 0.0),  # ç‰‡æ–¹None
        ]
        
        for raw_text, interpreted_text, expected_min in test_cases:
            similarity = calculate_levenshtein_similarity(raw_text, interpreted_text)
            
            # åŸºæœ¬çš„ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
            assert 0.0 <= similarity <= 1.0, f"é¡ä¼¼åº¦ãŒç¯„å›²å¤–: {similarity}"
            
            # å®Œå…¨ä¸€è‡´ã®å ´åˆã¯1.0ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if raw_text == interpreted_text and raw_text is not None:
                assert similarity == 1.0, f"å®Œå…¨ä¸€è‡´ãªã®ã«1.0ã§ãªã„: {similarity}"

    def test_calculate_semantic_similarity(self):
        """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦è¨ˆç®—ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            ("é ­ç—›", "é ­ç—›", 1.0),  # å®Œå…¨ä¸€è‡´
            ("é ­ç—›", "ãšã¤ã†", 0.0),  # å®Œå…¨ä¸ä¸€è‡´
            ("3æ—¥å‰ã‹ã‚‰é ­ç—›ã‚ã‚Š", "3æ—¥å‰ã‹ã‚‰é ­ç—›ãŒå‡ºç¾", 0.3),  # éƒ¨åˆ†ä¸€è‡´
            ("", "", 1.0),  # ä¸¡æ–¹ç©ºæ–‡å­—
            ("é ­ç—›", "", 0.0),  # ç‰‡æ–¹ç©ºæ–‡å­—
            (None, None, 1.0),  # ä¸¡æ–¹None
            ("é ­ç—›", None, 0.0),  # ç‰‡æ–¹None
        ]
        
        for raw_text, interpreted_text, expected_min in test_cases:
            similarity = calculate_semantic_similarity(raw_text, interpreted_text)
            
            # åŸºæœ¬çš„ãªç¯„å›²ãƒã‚§ãƒƒã‚¯
            assert 0.0 <= similarity <= 1.0, f"é¡ä¼¼åº¦ãŒç¯„å›²å¤–: {similarity}"
            
            # å®Œå…¨ä¸€è‡´ã®å ´åˆã¯1.0ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            if raw_text == interpreted_text and raw_text is not None:
                assert similarity == 1.0, f"å®Œå…¨ä¸€è‡´ãªã®ã«1.0ã§ãªã„: {similarity}"

    def test_should_review(self):
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦å¦åˆ¤å®šãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            (0.9, 0.9, False),  # é«˜ä¿¡é ¼åº¦ãƒ»é«˜é¡ä¼¼åº¦
            (0.5, 0.9, True),   # ä½ä¿¡é ¼åº¦ãƒ»é«˜é¡ä¼¼åº¦
            (0.9, 0.5, True),   # é«˜ä¿¡é ¼åº¦ãƒ»ä½é¡ä¼¼åº¦
            (0.5, 0.5, True),   # ä½ä¿¡é ¼åº¦ãƒ»ä½é¡ä¼¼åº¦
            (None, 0.9, True),  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚
            (0.9, None, True),  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚
        ]
        
        for confidence, similarity, expected in test_cases:
            result = should_review(confidence, similarity)
            assert result == expected, f"åˆ¤å®šçµæœãŒæœŸå¾…å€¤ã¨ç•°ãªã‚‹: confidence={confidence}, similarity={similarity}, expected={expected}, actual={result}"

    def test_process_extracted_items(self, sample_raw_items, sample_interpreted_items):
        """æŠ½å‡ºã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        # å®Ÿè¡Œ
        jsonb_data, needs_review, overall_confidence = process_extracted_items(
            sample_raw_items, sample_interpreted_items
        )
        
        # æ¤œè¨¼
        assert isinstance(jsonb_data, dict)
        assert isinstance(needs_review, bool)
        assert isinstance(overall_confidence, float)
        assert 0.0 <= overall_confidence <= 1.0
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼
        for item_name in ["ä¸»è¨´", "ç¾ç—…æ­´", "æ—¢å¾€æ­´"]:
            if item_name in jsonb_data:
                item_data = jsonb_data[item_name]
                assert "raw_text" in item_data
                assert "interpreted_text" in item_data
                assert "similarity_score" in item_data
                assert "confidence_score" in item_data
                assert "needs_review" in item_data

    @pytest.mark.asyncio
    async def test_complete_extraction_workflow(self, sample_image_data):
        """å®Œå…¨æŠ½å‡ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.extract_raw_data_from_image') as mock_extract, \
             patch('app.services.gemini_service.interpret_extracted_data') as mock_interpret, \
             patch('app.services.similarity_service.calculate_levenshtein_similarity') as mock_lev, \
             patch('app.services.similarity_service.calculate_semantic_similarity') as mock_sem, \
             patch('app.services.similarity_service.should_review') as mock_review:
            
            # ãƒ¢ãƒƒã‚¯ã®è¨­å®š
            mock_extract.return_value = [{"item_name": "ä¸»è¨´", "raw_text": "é ­ç—›"}]
            mock_interpret.return_value = [{"item_name": "ä¸»è¨´", "interpreted_text": "é ­ç—›"}]
            mock_lev.return_value = 1.0
            mock_sem.return_value = 1.0
            mock_review.return_value = False
            
            # å®Ÿè¡Œ
            raw_result, interpreted_result = await extract_and_interpret_data(sample_image_data)
            
            # æ¤œè¨¼
            assert len(raw_result) > 0
            assert len(interpreted_result) > 0
            assert mock_extract.call_count == 1
            assert mock_interpret.call_count == 1

    @pytest.mark.asyncio
    async def test_error_handling(self, sample_image_data):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹ãƒ¢ãƒƒã‚¯
            mock_genai.GenerativeModel.side_effect = Exception("API Error")
            
            # å®Ÿè¡Œã¨ã‚¨ãƒ©ãƒ¼ç¢ºèª
            with pytest.raises(Exception):
                await extract_raw_data_from_image(sample_image_data)

    @pytest.mark.asyncio
    async def test_performance(self, sample_image_data, sample_raw_items):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ¢ãƒƒã‚¯
            mock_model = MagicMock()
            mock_response = MagicMock()
            mock_response.text = json.dumps(sample_raw_items)
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # å®Ÿè¡Œæ™‚é–“æ¸¬å®š
            import time
            start_time = time.time()
            result = await extract_raw_data_from_image(sample_image_data)
            end_time = time.time()
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼ï¼ˆãƒ¢ãƒƒã‚¯ãªã®ã§é«˜é€Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰
            execution_time = end_time - start_time
            assert execution_time < 1.0, f"å®Ÿè¡Œæ™‚é–“ãŒé•·ã™ãã‚‹: {execution_time}ç§’"
            assert len(result) > 0

    def test_data_integrity(self, sample_raw_items, sample_interpreted_items):
        """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ¤œè¨¼
        for item in sample_raw_items:
            assert 'item_name' in item
            assert 'raw_text' in item
            assert isinstance(item['item_name'], str)
            assert isinstance(item['raw_text'], str)
        
        for item in sample_interpreted_items:
            assert 'item_name' in item
            assert 'interpreted_text' in item
            assert isinstance(item['item_name'], str)
            assert isinstance(item['interpreted_text'], str)
        
        # é …ç›®åã®ä¸€è‡´ç¢ºèª
        raw_names = {item['item_name'] for item in sample_raw_items}
        interpreted_names = {item['item_name'] for item in sample_interpreted_items}
        assert raw_names == interpreted_names, "ç”ŸæŠ½å‡ºã¨è§£é‡ˆçµæœã®é …ç›®åãŒä¸€è‡´ã—ãªã„"


class TestLevel1ExtractionServiceAdvanced:
    """Level 1 æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹é«˜åº¦ãƒ†ã‚¹ãƒˆ"""

    @pytest.mark.asyncio
    async def test_extraction_with_empty_data(self):
        """ç©ºãƒ‡ãƒ¼ã‚¿ã§ã®æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ç©ºãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒƒã‚¯
            mock_model = MagicMock()
            mock_response = MagicMock()
            mock_response.text = json.dumps([])
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # å®Ÿè¡Œ
            result = await extract_raw_data_from_image(b"empty_image")
            
            # æ¤œè¨¼
            assert isinstance(result, list)
            assert len(result) == 0

    @pytest.mark.asyncio
    async def test_extraction_with_malformed_json(self):
        """ä¸æ­£ãªJSONã§ã®æŠ½å‡ºãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ä¸æ­£ãªJSONã®ãƒ¢ãƒƒã‚¯
            mock_model = MagicMock()
            mock_response = MagicMock()
            mock_response.text = "invalid json"
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # å®Ÿè¡Œã¨ã‚¨ãƒ©ãƒ¼ç¢ºèª
            with pytest.raises(Exception):
                await extract_raw_data_from_image(b"malformed_image")

    def test_similarity_edge_cases(self):
        """é¡ä¼¼åº¦è¨ˆç®—ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # éå¸¸ã«é•·ã„æ–‡å­—åˆ—
        long_text1 = "é ­ç—›" * 1000
        long_text2 = "é ­ç—›" * 1000
        similarity = calculate_levenshtein_similarity(long_text1, long_text2)
        assert similarity == 1.0
        
        # ç‰¹æ®Šæ–‡å­—
        special_text1 = "é ­ç—›@#$%^&*()"
        special_text2 = "é ­ç—›@#$%^&*()"
        similarity = calculate_levenshtein_similarity(special_text1, special_text2)
        assert similarity == 1.0
        
        # Unicodeæ–‡å­—
        unicode_text1 = "é ­ç—›ğŸ¤•ğŸ˜·"
        unicode_text2 = "é ­ç—›ğŸ¤•ğŸ˜·"
        similarity = calculate_levenshtein_similarity(unicode_text1, unicode_text2)
        assert similarity == 1.0

    def test_review_logic_comprehensive(self):
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ­ã‚¸ãƒƒã‚¯ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            # (confidence, similarity, error_occurred, expected)
            (0.95, 0.95, False, False),  # é«˜ä¿¡é ¼åº¦ãƒ»é«˜é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ãªã—
            (0.95, 0.95, True, True),   # é«˜ä¿¡é ¼åº¦ãƒ»é«˜é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ã‚ã‚Š
            (0.5, 0.95, False, True),   # ä½ä¿¡é ¼åº¦ãƒ»é«˜é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ãªã—
            (0.95, 0.5, False, True),   # é«˜ä¿¡é ¼åº¦ãƒ»ä½é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ãªã—
            (0.5, 0.5, False, True),    # ä½ä¿¡é ¼åº¦ãƒ»ä½é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ãªã—
            (0.5, 0.5, True, True),     # ä½ä¿¡é ¼åº¦ãƒ»ä½é¡ä¼¼åº¦ãƒ»ã‚¨ãƒ©ãƒ¼ã‚ã‚Š
        ]
        
        for confidence, similarity, error_occurred, expected in test_cases:
            # should_reviewé–¢æ•°ãŒ error_occurred ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            try:
                result = should_review(confidence, similarity, error_occurred)
            except TypeError:
                # å¤ã„ã‚·ã‚°ãƒãƒãƒ£ã®å ´åˆ
                result = should_review(confidence, similarity)
                if error_occurred:
                    result = True  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯å¸¸ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦
            
            assert result == expected, f"ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ¤å®šãŒæœŸå¾…å€¤ã¨ç•°ãªã‚‹: confidence={confidence}, similarity={similarity}, error_occurred={error_occurred}, expected={expected}, actual={result}"

    def test_process_extracted_items_edge_cases(self):
        """æŠ½å‡ºã‚¢ã‚¤ãƒ†ãƒ å‡¦ç†ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã®ãƒªã‚¹ãƒˆ
        jsonb_data, needs_review, overall_confidence = process_extracted_items([], [])
        assert isinstance(jsonb_data, dict)
        assert isinstance(needs_review, bool)
        assert isinstance(overall_confidence, float)
        
        # ä¸ä¸€è‡´ã™ã‚‹é …ç›®æ•°
        raw_items = [{"item_name": "ä¸»è¨´", "raw_text": "é ­ç—›"}]
        interpreted_items = [
            {"item_name": "ä¸»è¨´", "interpreted_text": "é ­ç—›"},
            {"item_name": "ç¾ç—…æ­´", "interpreted_text": "è¿½åŠ é …ç›®"}
        ]
        jsonb_data, needs_review, overall_confidence = process_extracted_items(raw_items, interpreted_items)
        assert "ä¸»è¨´" in jsonb_data
        assert "ç¾ç—…æ­´" in jsonb_data

    @pytest.mark.asyncio
    async def test_concurrent_extraction(self):
        """ä¸¦è¡ŒæŠ½å‡ºå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ¢ãƒƒã‚¯
            mock_model = MagicMock()
            mock_response = MagicMock()
            mock_response.text = json.dumps([{"item_name": "ä¸»è¨´", "raw_text": "é ­ç—›"}])
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
            mock_genai.configure = MagicMock()
            
            # è¤‡æ•°ã®ä¸¦è¡Œå®Ÿè¡Œ
            tasks = [
                extract_raw_data_from_image(f"image_{i}".encode())
                for i in range(5)
            ]
            results = await asyncio.gather(*tasks)
            
            # æ¤œè¨¼
            assert len(results) == 5
            for result in results:
                assert isinstance(result, list)
                assert len(result) > 0

    def test_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""
        import gc
        
        # å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        large_raw_items = [
            {"item_name": f"é …ç›®{i}", "raw_text": "ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿" * 100}
            for i in range(100)
        ]
        large_interpreted_items = [
            {"item_name": f"é …ç›®{i}", "interpreted_text": "è§£é‡ˆãƒ‡ãƒ¼ã‚¿" * 100}
            for i in range(100)
        ]
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨å‰
        gc.collect()
        
        # å‡¦ç†å®Ÿè¡Œ
        jsonb_data, needs_review, overall_confidence = process_extracted_items(
            large_raw_items, large_interpreted_items
        )
        
        # çµæœæ¤œè¨¼ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã‚’é™¤å¤–ã—ã¦é …ç›®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼‰
        item_keys = [key for key in jsonb_data.keys() if key.startswith('é …ç›®')]
        assert len(item_keys) == 100
        assert isinstance(needs_review, bool)
        assert isinstance(overall_confidence, float)
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        del jsonb_data, large_raw_items, large_interpreted_items
        gc.collect()

    def test_unicode_handling(self):
        """Unicodeæ–‡å­—å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        unicode_raw_items = [
            {"item_name": "ä¸»è¨´", "raw_text": "é ­ç—›ğŸ¤•"},
            {"item_name": "ç¾ç—…æ­´", "raw_text": "ç—‡çŠ¶ğŸ˜·ãŒæ‚ªåŒ–"},
        ]
        unicode_interpreted_items = [
            {"item_name": "ä¸»è¨´", "interpreted_text": "é ­ç—›ğŸ¤•"},
            {"item_name": "ç¾ç—…æ­´", "interpreted_text": "ç—‡çŠ¶ğŸ˜·ãŒæ‚ªåŒ–ã—ã¦ã„ã‚‹"},
        ]
        
        jsonb_data, needs_review, overall_confidence = process_extracted_items(
            unicode_raw_items, unicode_interpreted_items
        )
        
        assert "ä¸»è¨´" in jsonb_data
        assert "ç¾ç—…æ­´" in jsonb_data
        assert jsonb_data["ä¸»è¨´"]["raw_text"] == "é ­ç—›ğŸ¤•"

    @pytest.mark.asyncio
    async def test_timeout_handling(self):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        with patch('app.services.gemini_service.genai') as mock_genai:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’æ¨¡æ“¬
            mock_genai.GenerativeModel.side_effect = asyncio.TimeoutError("Request timeout")
            
            # å®Ÿè¡Œã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç¢ºèª
            with pytest.raises(asyncio.TimeoutError):
                await extract_raw_data_from_image(b"timeout_image")

    def test_boundary_values(self):
        """å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ"""
        # æœ€å°å€¤
        assert calculate_levenshtein_similarity("", "") == 1.0
        assert calculate_semantic_similarity("", "") == 1.0
        
        # æœ€å¤§å€¤ï¼ˆå®Ÿç”¨çš„ãªç¯„å›²ï¼‰
        max_text = "a" * 10000
        similarity = calculate_levenshtein_similarity(max_text, max_text)
        assert similarity == 1.0
        
        # å¢ƒç•Œå€¤ã§ã®é¡ä¼¼åº¦
        assert 0.0 <= calculate_levenshtein_similarity("a", "b") <= 1.0
        assert 0.0 <= calculate_semantic_similarity("a", "b") <= 1.0 